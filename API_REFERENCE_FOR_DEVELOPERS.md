# Nexus AI SDK - Complete API Reference for Application Developers

**Package**: `keystone-ai` (import as `nexusai`)
**Version**: 0.2.1a1 (Alpha)
**Last Updated**: 2025-10-06

---

## ğŸ“¦ Installation

```bash
# Install alpha version (required --pre flag)
pip install keystone-ai --pre

# Or use specific version
pip install keystone-ai==0.2.1a1 --pre

# Verify installation
python -c "import nexusai; print(nexusai.__version__)"
```

**å›½å†…é•œåƒåŠ é€Ÿ**ï¼š
```bash
# æ¸…åé•œåƒ
pip install keystone-ai --pre -i https://pypi.tuna.tsinghua.edu.cn/simple

# é˜¿é‡Œäº‘é•œåƒ
pip install keystone-ai --pre -i https://mirrors.aliyun.com/pypi/simple/
```

---

## ğŸš€ Quick Start

```python
from nexusai import NexusAIClient

# Initialize client (uses production API automatically)
client = NexusAIClient(api_key="your_api_key_here")

# Generate text
response = client.text.generate("Hello, AI!")
print(response.text)
```

---

## ğŸ¯ Supported Models

### Text Generation Models

**ä¸‰æ¡£æ¨¡å‹ä½“ç³»**ï¼š

#### ğŸ¥‡ é«˜ç«¯æ¨¡å‹ (Premium Tier)
| Model | Speed | Cost | Best For | Temperature Range |
|-------|-------|------|----------|-------------------|
| `gpt-5` | âš¡âš¡âš¡ **æœ€å¿«** | ğŸ’° æœ€è´µ | å¤æ‚æ¨ç† + é€Ÿåº¦è¦æ±‚ | 0.0 - 2.0 |
| `gemini-2.5-pro` | âš¡âš¡ è¾ƒæ…¢ | ğŸ’° æœ€è´µ | å¤æ‚æ¨ç†ã€æ·±åº¦åˆ†æ | 0.0 - 2.0 |

#### ğŸ¥ˆ ä¸­ç«¯æ¨¡å‹ (Standard Tier)
| Model | Speed | Cost | Best For | Temperature Range |
|-------|-------|------|----------|-------------------|
| `gpt-5-mini` | âš¡âš¡âš¡ å¿« | ğŸ’°ğŸ’° ä¸­ç­‰ | **æ¨è** - é€šç”¨ä»»åŠ¡ã€å¯¹è¯ | 0.0 - 2.0 |
| `gpt-4o-mini` | âš¡âš¡âš¡ å¿« | ğŸ’°ğŸ’° ä¸­ç­‰ | é€šç”¨ä»»åŠ¡ã€å¯¹è¯ | 0.0 - 2.0 |

#### ğŸ¥‰ ç»æµæ¨¡å‹ (Budget Tier)
| Model | Speed | Cost | Best For | Temperature Range |
|-------|-------|------|----------|-------------------|
| `deepseek-v3.2-exp` | âš¡âš¡ ä¸­ç­‰ | ğŸ’°ğŸ’°ğŸ’° **æœ€ä¾¿å®œ** | æˆæœ¬æ•æ„Ÿå‹åº”ç”¨ | 0.0 - 2.0 |

**Default Model**: `gpt-5-mini` (if not specified)

**æ¨¡å‹é€‰æ‹©å»ºè®®**ï¼š
- **gpt-5**: éœ€è¦é¡¶çº§æ¨ç†èƒ½åŠ› + æœ€å¿«å“åº”ï¼ˆå¦‚å®æ—¶å®¢æœã€å¤æ‚åˆ†æï¼‰
- **gemini-2.5-pro**: éœ€è¦é¡¶çº§æ¨ç†èƒ½åŠ›ï¼Œå¯¹é€Ÿåº¦ä¸æ•æ„Ÿï¼ˆå¦‚æ·±åº¦ç ”ç©¶ã€é•¿æ–‡åˆ†æï¼‰
- **gpt-5-mini**: æ—¥å¸¸é€šç”¨ä»»åŠ¡çš„æœ€ä½³é€‰æ‹©ï¼ˆæ¨èï¼‰
- **gpt-4o-mini**: å¤‡é€‰é€šç”¨æ¨¡å‹
- **deepseek-v3.2-exp**: å¤§æ‰¹é‡ã€æˆæœ¬æ•æ„Ÿåœºæ™¯ï¼ˆå¦‚æ‰¹é‡ç¿»è¯‘ã€ç®€å•åˆ†ç±»ï¼‰

**Usage Example**:
```python
# é«˜ç«¯æ¨¡å‹ - å¿«é€Ÿ + å¤æ‚æ¨ç†
response = client.text.generate(
    prompt="åˆ†æè¿™ä»½å¤æ‚çš„æ³•å¾‹åˆåŒï¼Œæ‰¾å‡ºæ½œåœ¨é£é™©",
    model="gpt-5",  # æœ€å¿«çš„é«˜ç«¯æ¨¡å‹
    temperature=0.3
)

# é«˜ç«¯æ¨¡å‹ - æ·±åº¦åˆ†æ
response = client.text.generate(
    prompt="å¯¹è¿™ç¯‡å­¦æœ¯è®ºæ–‡è¿›è¡Œæ·±åº¦æ‰¹åˆ¤æ€§åˆ†æ",
    model="gemini-2.5-pro",  # æœ€å¼ºæ¨ç†èƒ½åŠ›
    temperature=0.3
)

# ä¸­ç«¯æ¨¡å‹ - æ¨èç”¨äºå¤§å¤šæ•°åœºæ™¯
response = client.text.generate(
    prompt="æ€»ç»“è¿™ç¯‡æ–‡ç« çš„è¦ç‚¹",
    model="gpt-5-mini",  # é»˜è®¤æ¨è
    temperature=0.7
)

# ç»æµæ¨¡å‹ - æˆæœ¬ä¼˜å…ˆ
response = client.text.generate(
    prompt="å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡",
    model="deepseek-v3.2-exp",  # æœ€ä¾¿å®œ
    temperature=0.5
)
```

---

### Image Generation Models

| Model | Quality | Speed | Best For |
|-------|---------|-------|----------|
| `doubao-seedream-4-0-250828` | ğŸŒŸğŸŒŸğŸŒŸ é«˜è´¨é‡ | âš¡âš¡âš¡ å¿« | **é»˜è®¤æ¨è** - é€šç”¨å›¾ç‰‡ç”Ÿæˆ |
| `gemini-2.5-flash-image` | ğŸŒŸğŸŒŸğŸŒŸ é«˜è´¨é‡ | âš¡âš¡ ä¸­ç­‰ | å¤‡é€‰æ–¹æ¡ˆ |

**Default Model**: `doubao-seedream-4-0-250828` (if not specified)

**æ¨¡å‹é€‰æ‹©å»ºè®®**ï¼š
- **doubao-seedream-4-0-250828**: å­—èŠ‚è±†åŒ…å³æ¢¦æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ã€è´¨é‡é«˜ï¼ˆæ¨èï¼‰
- **gemini-2.5-flash-image**: Google Geminiå›¾ç‰‡æ¨¡å‹ï¼Œå¤‡é€‰æ–¹æ¡ˆ

**Supported Aspect Ratios**:
```python
"1:1"    # Square (1024x1024)
"16:9"   # Landscape widescreen (1792x1024)
"9:16"   # Portrait widescreen (1024x1792)
"4:3"    # Standard landscape (1365x1024)
"3:4"    # Standard portrait (1024x1365)
"21:9"   # Ultra-wide (2389x1024)
```

**âŒ Not Supported**: Custom pixel dimensions (e.g., `1920x1080`)

**Usage Example**:
```python
# Single image (uses default model)
image = client.image.generate(
    prompt="A professional business headshot, white background",
    aspect_ratio="1:1",
    num_images=1
)
print(f"Image URL: {image.url}")

# With explicit model selection
image = client.image.generate(
    prompt="A professional business headshot, white background",
    model="doubao-seedream-4-0-250828",  # é»˜è®¤æ¨èæ¨¡å‹
    aspect_ratio="1:1",
    num_images=1
)

# Batch generation (e.g., for employee matrix)
images = client.image.generate(
    prompt="Professional headshot, neutral background, diverse person",
    model="doubao-seedream-4-0-250828",
    aspect_ratio="1:1",
    num_images=8  # Generate 8 images at once
)
for img in images:
    print(f"Image {img.index + 1}: {img.url}")
```

---

## ğŸ“š Core API Reference

### 1. Text Generation

#### `client.text.generate()`

**Basic Usage**:
```python
response = client.text.generate(
    prompt="Write a poem about spring",
    model="gpt-5-mini",         # Optional, defaults to gpt-5-mini
    temperature=0.7,            # Optional, 0.0-2.0, default 0.7
    max_tokens=500,             # Optional, default None (unlimited)
    top_p=0.9,                  # Optional, 0.0-1.0, default None
    stream=False                # Optional, set True for streaming
)

print(response.text)
print(f"Tokens: {response.usage.total_tokens}")
```

**Response Object**:
```python
{
    "text": str,              # Generated text
    "usage": {
        "prompt_tokens": int,
        "completion_tokens": int,
        "total_tokens": int
    },
    "model": str,             # Model used
    "finish_reason": str      # "stop", "length", etc.
}
```

---

#### `client.text.generate_stream()`

**Streaming Usage**:
```python
for chunk in client.text.generate_stream(
    prompt="Tell me a long story",
    model="gpt-5-mini",
    temperature=0.8
):
    print(chunk.text, end="", flush=True)
print()  # New line after streaming
```

---

### 2. Image Generation

#### `client.image.generate()`

**Parameters**:
```python
image = client.image.generate(
    prompt=str,                              # Required: image description
    model="doubao-seedream-4-0-250828",      # Optional, default model
    aspect_ratio="16:9",                     # Required: one of the supported ratios
    num_images=1                             # Optional, 1-8, default 1
)
```

**Response Object** (single image):
```python
{
    "url": str,           # Image URL (valid for 24 hours)
    "width": int,         # Image width in pixels
    "height": int,        # Image height in pixels
    "index": int          # 0 for single image
}
```

**Response Object** (multiple images):
```python
[
    {"url": str, "width": int, "height": int, "index": 0},
    {"url": str, "width": int, "height": int, "index": 1},
    ...
]
```

**âš ï¸ Important Notes**:
1. **Style prompts**: Include style in main prompt (no separate `style` parameter)
   ```python
   # âœ… Correct
   prompt = "Cyberpunk style futuristic city, neon lights, rain"

   # âŒ Wrong (no style parameter supported)
   prompt = "Futuristic city", style = "cyberpunk"
   ```

2. **Aspect ratio only**: No custom pixel dimensions
   ```python
   # âœ… Correct
   aspect_ratio = "16:9"

   # âŒ Wrong
   size = "1920x1080"  # Not supported
   ```

---

### 3. Session Management (Conversations)

#### `client.sessions.create()`

**Create a Session**:
```python
session = client.sessions.create(
    name="Customer Support Chat",
    agent_config={
        "model": "gpt-5-mini",  # æ¨èä½¿ç”¨ä¸­ç«¯æ¨¡å‹
        "temperature": 0.7,
        "system_prompt": "You are a helpful customer support agent."
    }
)

print(f"Session ID: {session.session_id}")
```

---

#### `session.invoke()`

**Send Messages**:
```python
# First message
response = session.invoke("My name is Alice")
print(response.response.content)

# Follow-up (remembers context)
response = session.invoke("What's my name?")
print(response.response.content)  # Output: "Your name is Alice"
```

**Temporary Config Override**:
```python
# Override temperature for this message only
response = session.invoke(
    "Be creative and write a poem",
    config={"temperature": 1.5}  # Higher creativity for this message
)
# Session's base temperature remains 0.7
```

---

#### `session.history()`

**Get Conversation History**:
```python
history = session.history()

for message in history.messages:
    print(f"{message.role}: {message.content}")
    print(f"Timestamp: {message.created_at}")
```

---

### 4. Knowledge Base & RAG

#### `client.knowledge_bases.create()`

```python
kb = client.knowledge_bases.create(
    name="Company Documentation",
    description="Internal policies and procedures"
)
print(f"Knowledge Base ID: {kb.kb_id}")
```

---

#### `client.knowledge_bases.upload_document()`

**Upload and Process Document**:
```python
# Single-step upload
task = client.knowledge_bases.upload_document(
    kb_id=kb.kb_id,
    file="employee_handbook.pdf"
)

# Wait for processing
import time
while True:
    status = client.tasks.get(task.task_id)
    if status.status == "completed":
        print("Document processed!")
        break
    elif status.status == "failed":
        print(f"Failed: {status.error}")
        break
    time.sleep(2)
```

**Reuse Files Across Knowledge Bases**:
```python
# Upload once
file_meta = client.files.upload("shared_policy.pdf")

# Add to multiple knowledge bases
client.knowledge_bases.add_document("kb_sales", file_meta.file_id)
client.knowledge_bases.add_document("kb_support", file_meta.file_id)
client.knowledge_bases.add_document("kb_hr", file_meta.file_id)
```

---

#### `client.knowledge_bases.search()`

```python
results = client.knowledge_bases.search(
    query="What is the vacation policy?",
    knowledge_base_ids=[kb.kb_id],
    top_k=3  # Return top 3 most relevant chunks
)

for result in results.results:
    print(f"Score: {result.score}")
    print(f"Content: {result.content}")
    print(f"Source: {result.metadata.get('filename')}")
```

---

### 5. File Operations

#### `client.files.upload()`

```python
file_meta = client.files.upload("document.pdf")

print(f"File ID: {file_meta.file_id}")
print(f"Filename: {file_meta.filename}")
print(f"Size: {file_meta.file_size} bytes")
```

**Supported File Types**:
- Documents: `.pdf`, `.txt`, `.md`, `.docx`
- Audio: `.mp3`, `.wav`, `.m4a`, `.flac`
- Images: `.png`, `.jpg`, `.jpeg`, `.webp`
- âš ï¸ Not supported: `.json`, `.csv`, `.xlsx` (coming in v0.3.0)

---

#### `client.files.list()`

```python
response = client.files.list(page=1, per_page=20)

print(f"Total files: {response.total}")
for file in response.files:
    print(f"{file.filename} ({file.file_size} bytes)")
```

---

### 6. Audio Processing

#### `client.audio.transcribe()` (ASR)

```python
# Upload audio file
file_meta = client.files.upload("meeting.mp3")

# Transcribe
transcription = client.audio.transcribe(
    file_id=file_meta.file_id,
    language="zh"  # "zh" for Chinese, "en" for English
)

print(transcription.text)
```

#### `client.audio.text_to_speech()` (TTS)

âš ï¸ **Not Yet Implemented** - Coming in v0.3.0

---

## ğŸ” Configuration

### Environment Variables

Create a `.env` file:
```bash
# Required
NEXUS_API_KEY=your_api_key_here

# Optional (defaults shown)
NEXUS_BASE_URL=https://nexus-ai.juncai-ai.com/api/v1
NEXUS_TIMEOUT=30
NEXUS_MAX_RETRIES=3
```

### Code Configuration

```python
from nexusai import NexusAIClient

# Production (default)
client = NexusAIClient(api_key="your_key")

# Custom configuration
client = NexusAIClient(
    api_key="your_key",
    base_url="https://custom-api.example.com/api/v1",
    timeout=60,
    max_retries=5
)
```

---

## âš ï¸ Error Handling

```python
from nexusai import NexusAIClient
from nexusai.error import (
    APIError,
    AuthenticationError,
    RateLimitError,
    ValidationError,
    NotFoundError,
    APITimeoutError,
    NetworkError
)

client = NexusAIClient()

try:
    response = client.text.generate("Hello")
except AuthenticationError:
    print("Invalid API key")
except ValidationError as e:
    print(f"Invalid parameters: {e.validation_errors}")
except RateLimitError as e:
    print(f"Rate limited. Retry after {e.retry_after} seconds")
except APITimeoutError:
    print("Request timed out")
except NetworkError as e:
    if e.is_retryable:
        print("Network error, will retry")
except APIError as e:
    print(f"API error: {e}")
```

---

## ğŸ’¡ Best Practices

### 1. Model Selection

**æ–‡æœ¬æ¨¡å‹é€‰æ‹©å†³ç­–æ ‘**ï¼š

```python
# éœ€è¦æœ€å¼ºæ¨ç† + æœ€å¿«é€Ÿåº¦ï¼Ÿ â†’ gpt-5
model = "gpt-5"

# éœ€è¦æœ€å¼ºæ¨ç†ï¼Œé€Ÿåº¦ä¸é‡è¦ï¼Ÿ â†’ gemini-2.5-pro
model = "gemini-2.5-pro"

# æ—¥å¸¸é€šç”¨ä»»åŠ¡ï¼ˆæ¨èï¼‰ï¼Ÿ â†’ gpt-5-mini
model = "gpt-5-mini"

# å¤§æ‰¹é‡ã€æˆæœ¬æ•æ„Ÿï¼Ÿ â†’ deepseek-v3.2-exp
model = "deepseek-v3.2-exp"
```

**å›¾ç‰‡æ¨¡å‹é€‰æ‹©**ï¼š

```python
# é»˜è®¤æ¨èï¼ˆå¿«é€Ÿã€é«˜è´¨é‡ï¼‰
model = "doubao-seedream-4-0-250828"

# å¤‡é€‰æ–¹æ¡ˆ
model = "gemini-2.5-flash-image"
```

### 2. Temperature Guidelines

```python
# Factual/deterministic tasks (summaries, translations)
temperature = 0.0 - 0.3

# Balanced creativity (general conversation)
temperature = 0.7

# Creative tasks (stories, brainstorming)
temperature = 0.9 - 1.5
```

### 3. Session Management

```python
# Reuse sessions for multi-turn conversations
session = client.sessions.create(name="User Chat", agent_config={...})

# Don't create new session for each message!
# âŒ Bad
for message in messages:
    session = client.sessions.create(...)  # Wasteful!
    session.invoke(message)

# âœ… Good
session = client.sessions.create(...)
for message in messages:
    session.invoke(message)
```

### 4. File Management

```python
# Upload once, reuse across knowledge bases
file_meta = client.files.upload("large_document.pdf")
client.knowledge_bases.add_document("kb_1", file_meta.file_id)
client.knowledge_bases.add_document("kb_2", file_meta.file_id)
```

---

## ğŸ“Š Usage Quotas & Cost Control

### Recommended Quota Structure

**Free Tier**:
- Text: 50 generations/month (gpt-5-mini/gpt-4o-mini/deepseek only)
- Images: 20 images/month (doubao model only)
- Sessions: 5 active sessions
- Knowledge Bases: 1 KB, max 10 documents

**Pro Tier**:
- Text: 500 generations/month (all models including gpt-5/gemini-2.5-pro)
- Images: 200 images/month (all models)
- Sessions: Unlimited
- Knowledge Bases: 10 KBs, unlimited documents

### Cost Estimation Example

```python
def estimate_cost(num_employees, images_per_employee, model="doubao-seedream-4-0-250828"):
    """
    Estimate image generation cost

    Args:
        num_employees: Number of employees
        images_per_employee: Images per employee (1-3)
        model: Image model to use

    Returns:
        dict with cost breakdown
    """
    # Pricing (example - replace with actual)
    IMAGE_COST = {
        "doubao-seedream-4-0-250828": 1.5,  # Â¥1.5 per image
        "gemini-2.5-flash-image": 2.0       # Â¥2.0 per image
    }

    total_images = num_employees * images_per_employee
    cost_per_image = IMAGE_COST.get(model, 2.0)
    total_cost = total_images * cost_per_image

    return {
        "total_images": total_images,
        "cost_per_image": cost_per_image,
        "total_cost": total_cost,
        "currency": "CNY"
    }

# Example: 8 employees, 2 images each
estimate = estimate_cost(8, 2)
print(f"Total: Â¥{estimate['total_cost']} for {estimate['total_images']} images")
# Output: Total: Â¥32.0 for 16 images
```

---

## ğŸš§ Alpha Version Limitations

1. **Shared API Key**: All users use same key (individual keys in v0.3.0)
2. **No TTS**: Text-to-speech not implemented yet
3. **Limited File Types**: No JSON/CSV/XLSX support yet
4. **No Usage Tracking**: You need to implement quota tracking

---

## ğŸ“ Support

- **Documentation**: https://nexus-ai.juncai-ai.com/docs
- **GitHub Issues**: https://github.com/aidrshao/nexus-ai-sdk/issues
- **Email**: support@nexus-ai.com

---

## ğŸ”„ Changelog

See [CHANGELOG.md](CHANGELOG.md) for version history.

---

**Version**: 0.2.1a1
**Last Updated**: 2025-10-06
